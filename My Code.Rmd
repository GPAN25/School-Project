---
title: 'Causal Inference Final Project'
author: "Gaetano Pannia"
date: "11/28/2020"
output:
  html_document:
    df_print: kable
  pdf_document: default
---

```{r}
library(tidyverse)
library(dplyr)
library(broom)
library(knitr)
library(ggplot2)
library(Matching)
library(rdd)
library(haven)
library(stargazer)
```

retrieving and sorting the data
```{r}
data <- read_dta("C:/Users/G Pannia/Desktop/probation/data.dta")

# sample for original analysis
sample <- data[data$dist_from_cut >= -0.6 & data$dist_from_cut <=0.6,]
# Create a variable for the next GPA, imputing from nextGPA variable
sample$nextGPA_temp <- sample$nextGPA + sample$gpacutoff
# Create binary indicator for improving GPA in next term
sample$improve_GPA <- ifelse(sample$nextGPA_temp > sample$GPA_year1,1,0)
```

# Table 1

This table finds the mean and standard deviation for different columns in the data set and the cbind function is used to transform it into a table. 

```{r}
sample1 <- na.omit(sample$nextGPA)
sample2 <- na.omit(sample$gradin4) 
sample3 <- na.omit(sample$gradin5)
sample4 <- na.omit(sample$gradin6)
col1<-c(mean(sample$hsgrade_pct),mean(sample$totcredits_year1),mean(sample$age_at_entry),mean(sample$male),mean(sample$english),mean(sample$bpl_north_america),mean(sample$loc_campus1),mean(sample$loc_campus2),mean(sample$loc_campus3),mean(sample$dist_from_cut),mean(sample$probation_year1),mean(sample$probation_ever),mean(sample$left_school),mean(sample1),mean(sample$suspended_ever),mean(sample2),mean(sample3),mean(sample4))

col2<-c( sd(sample$hsgrade_pct), sd(sample$totcredits_year1), sd(sample$age_at_entry),sd(sample$male), sd(sample$english),sd(sample$bpl_north_america), sd(sample$loc_campus1), sd(sample$loc_campus2)  ,sd(sample$loc_campus3)  ,sd(sample$dist_from_cut)  , sd(sample$probation_year1) ,sd(sample$probation_ever),sd(sample$left_school) ,sd(sample1) ,sd(sample$suspended_ever),sd(sample2) ,sd(sample3) ,sd(sample4))

table1 <- cbind(col1,col2)


rownames(table1)=c("High school grade percentile", "Credits attempted in first year", "Age at entry" , "Male", "English is first language","Born in North America", "At Campus 1", "At Campus 2", "At Campus 3", "Distance from cutoff in 1st year",  "On probation after 1st year", "Ever on academic probation", "Left university after 1st evaluation", "Distance from cutoff at next evaluation", "Ever suspended", "Graduated by year 4", "Graduated by year 5", "Graduated by year 6")

colnames(table1)=c("Mean","SD")

print(table1)
```


# Figure 1
The below code is meant to replicate figure one from the study. Using the bin_id section of this code it allows us to replicate the circles which indicate the frequency of that occurence.

```{r}
G2 <- as.tibble(data$dist_from_cut)

bin_id = as.tibble(floor(G2*10))
G2$bin_id <- bin_id
Fr <- G2 %>% group_by(bin_id)  

show_smoothed = TRUE
bandwidth <- 0.6
formula <- y ~ 1 

G3 <- summarise(Fr, count = n(),
  value = mean(value, na.rm = TRUE))

ggplot(data = G3, mapping = aes(x = value, y = count, color = value>0)) +
  geom_point(aes(size = count), alpha = 1/3) +
  xlim(-1.5,1.2) + 
  geom_vline(xintercept = 0, linetype="dotted", 
                color = "blue", size=1.5) + 
  stat_smooth(method="lm", se=FALSE)  

```

# Table 3
The below data simply runs a regression on our dependent variables (probation_year1 and probation_ever) on a set of independent variables. We created new subsets of data so that these regressions would be possible to account for specific characteristics (such as male, female, english, etc...). Count functions were used to determine the amount of observations in each regression. Finally, cbind was using to organize this data into readable tables. 

```{r}
lowHS <- sample[sample$lowHS == 1, ]
highHS <- sample[sample$highHS == 1, ]
male <- sample[sample$male == 1, ]
female <- sample[sample$female == 1, ]
english <- sample[sample$english == 1, ]
noenglish <- sample[sample$noenglish == 1, ]
```

Probation After Year 1
```{r}
table3col1 <-lm(probation_year1 ~ gpalscutoff + gpaXgpalscutoff + gpaXgpagrcutoff,data = sample)

table3col2 <-lm(probation_year1 ~ gpalscutoff + gpaXgpalscutoff + gpaXgpagrcutoff,data = lowHS)

table3col3 <-lm(probation_year1 ~ gpalscutoff + gpaXgpalscutoff + gpaXgpagrcutoff,data = highHS)

table3col4 <-lm(probation_year1 ~ gpalscutoff + gpaXgpalscutoff + gpaXgpagrcutoff,data = male)

table3col5 <-lm(probation_year1 ~ gpalscutoff + gpaXgpalscutoff + gpaXgpagrcutoff,data = female)

table3col6 <-lm(probation_year1 ~ gpalscutoff + gpaXgpalscutoff + gpaXgpagrcutoff,data = english)

table3col7 <-lm(probation_year1 ~ gpalscutoff + gpaXgpalscutoff + gpaXgpagrcutoff,data = noenglish)

coef1<-coef(table3col1)[1:2]
coef2<-coef(table3col2)[1:2]
coef3<-coef(table3col3)[1:2]
coef4<-coef(table3col4)[1:2]
coef5<-coef(table3col5)[1:2]
coef6<-coef(table3col6)[1:2]
coef7<-coef(table3col7)[1:2]

col1<-c(coef1,count(sample))
col2<-c(coef2,count(lowHS))
col3<-c(coef3,count(highHS))
col4<-c(coef4,count(male))
col5<-c(coef5,count(female))
col6<-c(coef6,count(english))
col7<-c(coef6,count(noenglish))
table3 <- cbind(col1,col2,col3,col4,col5,col6,col7)


colnames(table3)=c("All","HS Below Median","Hs Above Median","Male","Female","English","NonEnglish")
rownames(table3)=c("Constant (control mean)","First year GPA < cutoff","Observations")
print(table3)
```


Ever on Probation

```{r}
table3Bcol1 <-lm(probation_ever ~ gpalscutoff + gpaXgpalscutoff + gpaXgpagrcutoff,data = sample)

table3Bcol2 <-lm(probation_ever ~ gpalscutoff + gpaXgpalscutoff + gpaXgpagrcutoff,data = lowHS)

table3Bcol3 <-lm(probation_ever ~ gpalscutoff + gpaXgpalscutoff + gpaXgpagrcutoff,data = highHS)

table3Bcol4 <-lm(probation_ever ~ gpalscutoff + gpaXgpalscutoff + gpaXgpagrcutoff,data = male)

table3Bcol5 <-lm(probation_ever ~ gpalscutoff + gpaXgpalscutoff + gpaXgpagrcutoff,data = female)

table3Bcol6 <-lm(probation_ever ~ gpalscutoff + gpaXgpalscutoff + gpaXgpagrcutoff,data = english)

table3Bcol7 <-lm(probation_ever ~ gpalscutoff + gpaXgpalscutoff + gpaXgpagrcutoff,data = noenglish)

coef1<-coef(table3Bcol1)[1:2]
coef2<-coef(table3Bcol2)[1:2]
coef3<-coef(table3Bcol3)[1:2]
coef4<-coef(table3Bcol4)[1:2]
coef5<-coef(table3Bcol5)[1:2]
coef6<-coef(table3Bcol6)[1:2]
coef7<-coef(table3Bcol7)[1:2]

col1<-c(coef1,count(sample))
col2<-c(coef2,count(lowHS))
col3<-c(coef3,count(highHS))
col4<-c(coef4,count(male))
col5<-c(coef5,count(female))
col6<-c(coef6,count(english))
col7<-c(coef6,count(noenglish))
table3B <- cbind(col1,col2,col3,col4,col5,col6,col7)


colnames(table3B)=c("All","HS Below Median","Hs Above Median","Male","Female","English","NonEnglish")
rownames(table3B)=c("Constant (control mean)","First year GPA < cutoff","Observations")
print(table3B)
```


# Simulation
$$
\begin{aligned}
School Research & = \varepsilon_S \\
Campus Activity & = \varepsilon_C \\
Knowledge Of Cutoff & = \unicode{x1D7D9}_{\{School Research + Campus Activity > 0 \}} \\
GPA No Sorting & = \alpha_G \\
Range & = \unicode{x1D7D9}_{\{1.5 > GPA No Sorting > 1.35 \}} \\
GPA & = GPA No Sorting * (1 - Knowledge of Cutoff * Range) + 1.5 * Knowledge Of Cutoff * Range\\ 
Probation & = \unicode{x1D7D9}_{\{GPA > Cutoff \}}\\
\end{aligned}

$$


$$
\varepsilon_S \overset{i.i.d.}{\sim} Normal(0,\sigma_D) \\
\varepsilon_C \overset{i.i.d.}{\sim} Normal(0,\sigma_Y) \\
\alpha_G \overset{i.i.d.}{\sim} Uniform(0.9,2.1) 
$$

```{r}
simulate_data <- function(n_obs, alpha = 0.5, theta = 0.5, beta = 0, sigma = 1, min = 0.9, max = 2.1,cutoff=1.5,delta=0){
  
  # Create a basic tibble with one row per observation
  data <- tibble(i=1:n_obs) %>%
    
    mutate(School_Research = rnorm(n_obs,beta,sigma)) %>%
    mutate(Campus_Activity = rnorm(n_obs,beta,sigma)) %>%
    mutate(Knowledge_Of_Cutoff = ifelse(School_Research + Campus_Activity > 0,1,0)) %>%
    mutate(GPA_No_Sorting = runif(n_obs,min, max)) %>%
    mutate(Range = ifelse(GPA_No_Sorting >1.35 & 1.5 > GPA_No_Sorting,1,0)) %>%
    mutate(GPA = ifelse(Knowledge_Of_Cutoff==1 & Range ==1,1.5,GPA_No_Sorting)) %>%
    mutate(Probation = ifelse(GPA>=cutoff,0,1)) 
    
  
  
  data
}

simulate_data(10)
sample <- simulate_data(100)
```

```{r}

estimator <- function(sample_data){

  ols <- lm(Probation ~ Knowledge_Of_Cutoff,sample_data)
  
  point_estimate <- coef(ols)['Knowledge_Of_Cutoff']
  
  ci = confint(ols,'Knowledge_Of_Cutoff',0.95)
  
  estimate = c(point_estimate,ci[1,1],ci[1,2])
  names(estimate) <- c('delta_hat','ci_lower','ci_upper')
  
  estimate
  }
```

```{r}

mcEstimates <- function(n_samples,n_obs){
  
  estimates <- as_tibble(t(sapply(1:n_samples, function(s){
    names(s) <- 'sample'
    
    # Randomize the real effect
    delta = rnorm(1,0,1)
    names(delta) <- 'delta'
    
    # Simulate data
    sample_data <- simulate_data(n_obs=n_obs,delta=delta)
    
    # Compute the sample estimate
    estimate <- estimator(sample_data)
    
    # Add sample index and true value of delta
    estimate <- c(s,delta,estimate)
    
    # Store the result
    estimate
    
    })))
  
  # Add some additional helper variables
  estimates <- estimates %>% 
    mutate(error = delta_hat - delta) %>%
    mutate(in_ci = as.integer((ci_lower <= delta) & (delta <= ci_upper)))
  
  }

# Test generating a small number of samples
estimates <- mcEstimates(n_samples=10,n_obs=100)

kable(estimates)

```

```{r}
# Generate a larger number of samples
estimates <- mcEstimates(100,100)
```

```{r}

# Bias estimate:
est_bias <- mean(estimates$error)

# MSE estimate
est_mse <- mean(estimates$error^2)

# Var estimate (this way doesn't require the true value of delta to be the same in all samples)
est_var <- est_mse - est_bias^2

# Coverage estimate
est_coverage <- mean(estimates$in_ci)

est_stats <- tibble(statistic=c('bias','variance','mse','coverage'),estimate=c(est_bias,est_mse,est_var,est_coverage))

est_stats
```

```{r}

t_bias <- t.test(estimates$error)
t_coverage <- t.test(estimates$in_ci,mu=0.95)

test_results <- map_df(list(t_bias,t_coverage),tidy) %>%
  mutate(statistic = c('Bias','Coverage')) %>%
  mutate(H_0 = c(0,0.95))

test_results[c('statistic','estimate','H_0','p.value','conf.low','conf.high')]

```


